{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tranfer learning dog breeds classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alexchernov/anaconda3/envs/deep-learning/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexchernov/anaconda3/envs/deep-learning/lib/python3.6/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNet(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "preds = Dense(133, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.engine.input_layer.InputLayer object at 0x11082e4e0> False\n",
      "1 <keras.layers.convolutional.ZeroPadding2D object at 0x632314048> False\n",
      "2 <keras.layers.convolutional.Conv2D object at 0x632314390> False\n",
      "3 <keras.layers.normalization.BatchNormalization object at 0x632314588> False\n",
      "4 <keras.layers.advanced_activations.ReLU object at 0x632314c88> False\n",
      "5 <keras.layers.convolutional.DepthwiseConv2D object at 0x6323145c0> False\n",
      "6 <keras.layers.normalization.BatchNormalization object at 0x632368080> False\n",
      "7 <keras.layers.advanced_activations.ReLU object at 0x6323ff908> False\n",
      "8 <keras.layers.convolutional.Conv2D object at 0x6324ae908> False\n",
      "9 <keras.layers.normalization.BatchNormalization object at 0x63246aeb8> False\n",
      "10 <keras.layers.advanced_activations.ReLU object at 0x63242b588> False\n",
      "11 <keras.layers.convolutional.ZeroPadding2D object at 0x63250b160> False\n",
      "12 <keras.layers.convolutional.DepthwiseConv2D object at 0x63250b9b0> False\n",
      "13 <keras.layers.normalization.BatchNormalization object at 0x6325bb5f8> False\n",
      "14 <keras.layers.advanced_activations.ReLU object at 0x63250b748> False\n",
      "15 <keras.layers.convolutional.Conv2D object at 0x632653f60> False\n",
      "16 <keras.layers.normalization.BatchNormalization object at 0x63262f2b0> False\n",
      "17 <keras.layers.advanced_activations.ReLU object at 0x6325f3470> False\n",
      "18 <keras.layers.convolutional.DepthwiseConv2D object at 0x63273b908> False\n",
      "19 <keras.layers.normalization.BatchNormalization object at 0x6327814e0> False\n",
      "20 <keras.layers.advanced_activations.ReLU object at 0x6326bdc50> False\n",
      "21 <keras.layers.convolutional.Conv2D object at 0x6328233c8> False\n",
      "22 <keras.layers.normalization.BatchNormalization object at 0x6327dbda0> False\n",
      "23 <keras.layers.advanced_activations.ReLU object at 0x63284b748> False\n",
      "24 <keras.layers.convolutional.ZeroPadding2D object at 0x6328c0048> False\n",
      "25 <keras.layers.convolutional.DepthwiseConv2D object at 0x6328a1c88> False\n",
      "26 <keras.layers.normalization.BatchNormalization object at 0x63292e6d8> False\n",
      "27 <keras.layers.advanced_activations.ReLU object at 0x6328a1be0> False\n",
      "28 <keras.layers.convolutional.Conv2D object at 0x6329680f0> False\n",
      "29 <keras.layers.normalization.BatchNormalization object at 0x632985fd0> False\n",
      "30 <keras.layers.advanced_activations.ReLU object at 0x632949e80> False\n",
      "31 <keras.layers.convolutional.DepthwiseConv2D object at 0x632aba470> False\n",
      "32 <keras.layers.normalization.BatchNormalization object at 0x632a70c50> False\n",
      "33 <keras.layers.advanced_activations.ReLU object at 0x632adde48> False\n",
      "34 <keras.layers.convolutional.Conv2D object at 0x632afffd0> False\n",
      "35 <keras.layers.normalization.BatchNormalization object at 0x632b52e80> False\n",
      "36 <keras.layers.advanced_activations.ReLU object at 0x632b16160> False\n",
      "37 <keras.layers.convolutional.ZeroPadding2D object at 0x632c62860> False\n",
      "38 <keras.layers.convolutional.DepthwiseConv2D object at 0x632c1bef0> False\n",
      "39 <keras.layers.normalization.BatchNormalization object at 0x632c83be0> False\n",
      "40 <keras.layers.advanced_activations.ReLU object at 0x632c835c0> False\n",
      "41 <keras.layers.convolutional.Conv2D object at 0x632d46668> False\n",
      "42 <keras.layers.normalization.BatchNormalization object at 0x632d016d8> False\n",
      "43 <keras.layers.advanced_activations.ReLU object at 0x632d617f0> False\n",
      "44 <keras.layers.convolutional.DepthwiseConv2D object at 0x632d9c3c8> False\n",
      "45 <keras.layers.normalization.BatchNormalization object at 0x632df22b0> False\n",
      "46 <keras.layers.advanced_activations.ReLU object at 0x632e61358> False\n",
      "47 <keras.layers.convolutional.Conv2D object at 0x632ed4d30> False\n",
      "48 <keras.layers.normalization.BatchNormalization object at 0x632eb79e8> False\n",
      "49 <keras.layers.advanced_activations.ReLU object at 0x632e7d7b8> False\n",
      "50 <keras.layers.convolutional.DepthwiseConv2D object at 0x63300d3c8> False\n",
      "51 <keras.layers.normalization.BatchNormalization object at 0x632f9dda0> False\n",
      "52 <keras.layers.advanced_activations.ReLU object at 0x633033da0> False\n",
      "53 <keras.layers.convolutional.Conv2D object at 0x63306b2b0> False\n",
      "54 <keras.layers.normalization.BatchNormalization object at 0x6330a5dd8> False\n",
      "55 <keras.layers.advanced_activations.ReLU object at 0x633053ba8> False\n",
      "56 <keras.layers.convolutional.DepthwiseConv2D object at 0x6331b47b8> False\n",
      "57 <keras.layers.normalization.BatchNormalization object at 0x6331f8f60> False\n",
      "58 <keras.layers.advanced_activations.ReLU object at 0x633133b00> False\n",
      "59 <keras.layers.convolutional.Conv2D object at 0x633214668> False\n",
      "60 <keras.layers.normalization.BatchNormalization object at 0x63324f160> False\n",
      "61 <keras.layers.advanced_activations.ReLU object at 0x633214470> False\n",
      "62 <keras.layers.convolutional.DepthwiseConv2D object at 0x633339160> False\n",
      "63 <keras.layers.normalization.BatchNormalization object at 0x6333a47b8> False\n",
      "64 <keras.layers.advanced_activations.ReLU object at 0x633382f60> False\n",
      "65 <keras.layers.convolutional.Conv2D object at 0x633444668> False\n",
      "66 <keras.layers.normalization.BatchNormalization object at 0x6333ffcf8> False\n",
      "67 <keras.layers.advanced_activations.ReLU object at 0x633460cf8> False\n",
      "68 <keras.layers.convolutional.DepthwiseConv2D object at 0x633485f60> False\n",
      "69 <keras.layers.normalization.BatchNormalization object at 0x633528e10> False\n",
      "70 <keras.layers.advanced_activations.ReLU object at 0x63354bcf8> False\n",
      "71 <keras.layers.convolutional.Conv2D object at 0x6335c0d30> False\n",
      "72 <keras.layers.normalization.BatchNormalization object at 0x6335a19e8> False\n",
      "73 <keras.layers.advanced_activations.ReLU object at 0x6335683c8> False\n",
      "74 <keras.layers.convolutional.ZeroPadding2D object at 0x6336d03c8> False\n",
      "75 <keras.layers.convolutional.DepthwiseConv2D object at 0x6336fa6d8> False\n",
      "76 <keras.layers.normalization.BatchNormalization object at 0x633716ba8> False\n",
      "77 <keras.layers.advanced_activations.ReLU object at 0x6337169e8> False\n",
      "78 <keras.layers.convolutional.Conv2D object at 0x63372d748> False\n",
      "79 <keras.layers.normalization.BatchNormalization object at 0x63376a048> False\n",
      "80 <keras.layers.advanced_activations.ReLU object at 0x63372d518> False\n",
      "81 <keras.layers.convolutional.DepthwiseConv2D object at 0x63384e4a8> False\n",
      "82 <keras.layers.normalization.BatchNormalization object at 0x6338bc710> False\n",
      "83 <keras.layers.advanced_activations.ReLU object at 0x6337f7e80> False\n",
      "84 <keras.layers.convolutional.Conv2D object at 0x6339545c0> False\n",
      "85 <keras.layers.normalization.BatchNormalization object at 0x6339819e8> False\n",
      "86 <keras.layers.advanced_activations.ReLU object at 0x6339195c0> False\n",
      "87 <keras.layers.pooling.GlobalAveragePooling2D object at 0x63499aa58> True\n",
      "88 <keras.layers.core.Dense object at 0x63499aac8> True\n",
      "89 <keras.layers.core.Dense object at 0x63499add8> True\n",
      "90 <keras.layers.core.Dense object at 0x6349b38d0> True\n",
      "91 <keras.layers.core.Dense object at 0x6349cfe10> True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:87]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6680 images belonging to 133 classes.\n",
      "Found 835 images belonging to 133 classes.\n",
      "Found 836 images belonging to 133 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dogImages/train',\n",
    "    target_size=image_size,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    'dogImages/valid',\n",
    "    target_size=image_size,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dogImages/test',\n",
    "    target_size=image_size,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='keras_tl_dbc.hdf5', \n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "208/208 [==============================] - 508s 2s/step - loss: 1.0086 - accuracy: 0.6779 - val_loss: 1.0664 - val_accuracy: 0.6898\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.06643, saving model to keras_tl_dbc.hdf5\n",
      "Epoch 2/5\n",
      "208/208 [==============================] - 487s 2s/step - loss: 0.7988 - accuracy: 0.7435 - val_loss: 0.7524 - val_accuracy: 0.7102\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.06643 to 0.75235, saving model to keras_tl_dbc.hdf5\n",
      "Epoch 3/5\n",
      "208/208 [==============================] - 468s 2s/step - loss: 0.6285 - accuracy: 0.7911 - val_loss: 1.6260 - val_accuracy: 0.7293\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.75235\n",
      "Epoch 4/5\n",
      "208/208 [==============================] - 473s 2s/step - loss: 0.5179 - accuracy: 0.8281 - val_loss: 0.8941 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.75235\n",
      "Epoch 5/5\n",
      "208/208 [==============================] - 480s 2s/step - loss: 0.3951 - accuracy: 0.8673 - val_loss: 0.0106 - val_accuracy: 0.7054\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75235 to 0.01059, saving model to keras_tl_dbc.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x62ebcee80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    steps_per_epoch=step_size_train,\n",
    "    callbacks=[checkpointer],\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 59s 2s/step\n",
      "Test accuracy: 72.0096%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('keras_tl_dbc.hdf5')\n",
    "# get index of predicted dog breed for each image in test set\n",
    "loss, acc = model.evaluate_generator(test_generator, verbose=1)\n",
    "print('Test accuracy: %.4f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexchernov/anaconda3/envs/deep-learning/lib/python3.6/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f57c68023a41a781a8f04b19793415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[55,\n",
       " 111,\n",
       " 72,\n",
       " 85,\n",
       " 99,\n",
       " 49,\n",
       " 88,\n",
       " 78,\n",
       " 11,\n",
       " 87,\n",
       " 1,\n",
       " 44,\n",
       " 77,\n",
       " 85,\n",
       " 108,\n",
       " 69,\n",
       " 66,\n",
       " 45,\n",
       " 84,\n",
       " 31,\n",
       " 33,\n",
       " 55,\n",
       " 89,\n",
       " 121,\n",
       " 131,\n",
       " 77,\n",
       " 84]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "[np.argmax(test_generator.next()[1]) for iter in tqdm(range(len(test_generator)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
